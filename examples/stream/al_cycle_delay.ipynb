{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream active learning cycle with verification latency\n",
    "In this notebook, we will show how stream-based active learning strategies related to verification latency are compared. We showcase the methods available in the delay_wrapper package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T13:12:43.440304Z",
     "start_time": "2021-08-04T13:12:42.648382Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from collections import deque\n",
    "from skactiveml.classifier import PWC\n",
    "from skactiveml.stream import RandomSampler, PeriodicSampler\n",
    "from skactiveml.stream import FixedUncertainty, VariableUncertainty, Split, PAL\n",
    "from skactiveml.stream.budget_manager import FixedBudget, BIQF\n",
    "from skactiveml.stream.verification_latency import BaggingDelaySimulationWrapper, ForgettingWrapper, FuzzyDelaySimulationWrapper\n",
    "from skactiveml.utils import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize stream parameters \n",
    "Before the experiments can start, we need to construct a random data set. For this, we specify the necessary parameters in the cell below. To make the experiment repeatable, we will use the random_state object to generate all other random seeds, such that we only need to explicitely specify a single random seed. Furthermore, we specify the length of the data stream (stream_length), the size of the sliding window that defines the available training data (training_size) and the globally present verification latency, that affects all label acquisition equally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T13:12:43.445490Z",
     "start_time": "2021-08-04T13:12:43.441935Z"
    }
   },
   "outputs": [],
   "source": [
    "# random state that is used to generate random seeds\n",
    "random_state = np.random.RandomState(0)\n",
    "# number of instances that are provided to the classifier\n",
    "init_train_length = 10\n",
    "# the length of the data stream\n",
    "stream_length = 5000\n",
    "# the size of the sliding window that limits the training data\n",
    "training_size = 1000\n",
    "# the verification latency occuring after querying a label\n",
    "verification_latency = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed generation\n",
    "The get_randomseed function simplifies the generation of a new random seed from a given random state object. For this notebook, this random state object will be always the random_state obejct defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T13:12:43.458589Z",
     "start_time": "2021-08-04T13:12:43.447459Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_randomseed(random_state):\n",
    "    return random_state.randint(2**31-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and initialize data set\n",
    "The next block initializes the tested data set. We use scikit-learn to generate a random dataset with our pre-defined stream length. The data set consists of multiple parts. X represents the intances location within the feature space. The class for each instance is denoted by y. Furthermore, we need timestamps to be able to model the verification latency. In this notebook we show the effects of a constant verification latency, however, a verification latency per instance basis can be done by replacing the scalar value of verification_latency by a vector with an entry per instance. We distinguish between timestamps for an instance (tX) and the corresponding label (ty). Hence, given a query to sample the label y\\[i\\] for instance X\\[i\\] that occurs at tX\\[i\\], we will be able to incorporate the label y\\[i\\] beginning from ty\\[i\\].\n",
    "For models that need at least some initial training data, we generate samples to train an initial model. These are denoted by the suffix \"_init\", while all data used within the active learning cycle are denoted by the suffix \"_stream\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T13:12:43.478705Z",
     "start_time": "2021-08-04T13:12:43.460609Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the data stream\n",
    "X, center = sklearn.datasets.make_blobs(n_samples=init_train_length + stream_length, centers=30, random_state=get_randomseed(random_state), shuffle=True)\n",
    "y = center % 2\n",
    "X_init = X[:init_train_length, :]\n",
    "y_init = y[:init_train_length]\n",
    "X_stream = X[init_train_length:, :]\n",
    "y_stream = y[init_train_length:]\n",
    "# create the time stamps\n",
    "tX = np.arange(stream_length)\n",
    "ty = tX + verification_latency\n",
    "tX_init = tX[:init_train_length]\n",
    "ty_init = ty[:init_train_length]\n",
    "tX_stream = tX[init_train_length:]\n",
    "ty_stream = ty[init_train_length:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters for delay wrappers\n",
    "After initializing the dataset, we have to specify the parameters for each query strategy. \n",
    "K is used in BaggingDelaySimulationWrapper to specify the number of repeated simulations. The ForgettingWrapper uses w_train to assess the data that will still be available after the verification latency.  \n",
    "The delay_prior regularizes the class probability assessment used within BaggingDelaySimulationWrapper and FuzzyDelaySimulationWrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T13:12:43.494745Z",
     "start_time": "2021-08-04T13:12:43.490020Z"
    }
   },
   "outputs": [],
   "source": [
    "K = 2\n",
    "w_train = training_size\n",
    "delay_prior = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize query strategies\n",
    "Next, we initialize the classifier and the base query strategies that we want to compare. The base query strategies will be wrapped within one or multiple of the delay wrappers later on to make them aware of the verification latency. To guarantee that the classifier and the query strategies are not affected by previous repetitions, we use factory functions to separate the objects for each experiment run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T13:12:43.507245Z",
     "start_time": "2021-08-04T13:12:43.500795Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_factory = lambda: PWC(classes=[0,1], random_state= get_randomseed(random_state))\n",
    "missing_label = clf_factory().missing_label\n",
    "query_strategies_factories = {\n",
    "    # 'VariableUncertainty': VariableUncertainty(clf=clf, random_state=get_randomseed(random_state)),\n",
    "    'Split': lambda: Split(random_state=get_randomseed(random_state)),\n",
    "    'PAL': lambda: PAL(random_state=get_randomseed(random_state), budget_manager=BIQF( w=256, w_tol=20, budget=None, save_utilities=True))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the active learning cycle\n",
    "After all variables are initialized, we can start the experiment. The experiment loop below goes through all query strategies defined in query_strategies and use no delay wrapper (None), ForgettingWrapper, BaggingDelaySimulationWrapper, and FuzzyDelaySimulationWrapper on each strategy. For each experiment run, the average accuracy the selected query strategies will be displayed. Lastly, the accuracy over time will be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T13:19:57.685930Z",
     "start_time": "2021-08-04T13:12:43.515375Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for query_strategy_name, query_strategy_factory in query_strategies_factories.items():\n",
    "    delay_wrappers_factories = {\n",
    "        # 'None': lambda qs: qs,\n",
    "        'Forgetting': lambda qs: ForgettingWrapper(base_query_strategy=qs, w_train=w_train, random_state=get_randomseed(random_state)),\n",
    "        'BaggingDelaySimulation': lambda qs: BaggingDelaySimulationWrapper(base_query_strategy=qs, random_state=get_randomseed(random_state), K=K,  delay_prior=delay_prior),\n",
    "        'FuzzyDelaySimulation': lambda qs: FuzzyDelaySimulationWrapper(base_query_strategy=qs, random_state=get_randomseed(random_state),  delay_prior=delay_prior)\n",
    "    }\n",
    "    delay_wrappers_factories[\"Forgetting + Bagging\"] = lambda qs: delay_wrappers_factories[\"Forgetting\"](delay_wrappers_factories[\"BaggingDelaySimulation\"](qs))\n",
    "    delay_wrappers_factories[\"Forgetting + Fuzzy\"] = lambda qs: delay_wrappers_factories[\"Forgetting\"](delay_wrappers_factories[\"FuzzyDelaySimulation\"](qs))\n",
    "    print(\"Query Strategy: \",query_strategy_name,)\n",
    "    for delay_wrapper_name, delay_wrapper_factory in delay_wrappers_factories.items():\n",
    "        clf = clf_factory()\n",
    "        # initializing the query strategy\n",
    "        delay_wrapper = delay_wrapper_factory(query_strategy_factory())\n",
    "        # initializing the training data\n",
    "        X_train = deque(maxlen=training_size)\n",
    "        X_train.extend(X_init)\n",
    "        y_train = deque(maxlen=training_size)\n",
    "        y_train.extend(y_init)\n",
    "        # initialize the time stamps corresponding to the training data\n",
    "        tX_train = deque(maxlen=training_size)\n",
    "        tX_train.extend(tX_init)\n",
    "        ty_train = deque(maxlen=training_size)\n",
    "        ty_train.extend(ty_init)\n",
    "        # initializing the acquisition vector\n",
    "        acquisitions = deque(maxlen=training_size)\n",
    "        acquisitions.extend(np.full(len(y_train),True))\n",
    "        # train the model with the initially available data\n",
    "        clf.fit(X_train, y_train)\n",
    "        # initialize the list that stores the result of the classifier's prediction\n",
    "        correct_classifications = []\n",
    "        # initialize the number of acquired labels\n",
    "        count = 0\n",
    "        # iterate over the whole data stream\n",
    "        for t, (x_t, y_t , tX_t, ty_t) in enumerate(zip(X_stream, y_stream, tX_stream, ty_stream)):\n",
    "            # infer the currently available labels\n",
    "            # missing_label is used to denote unlabeled instances\n",
    "            X_cand = x_t.reshape([1, -1])\n",
    "            y_cand = y_t\n",
    "            tX_cand = tX_t\n",
    "            ty_cand = ty_t\n",
    "            y_train_current = np.array([y if ty < tX_cand and a else missing_label for ty, y, a in zip (ty_train, y_train, acquisitions)])\n",
    "            # train the classifier\n",
    "            clf.fit(np.array(X_train), np.array(y_train_current))\n",
    "            # evaluate the prediction of the classifier\n",
    "            correct_classifications.append(clf.predict(X_cand)[0] == y_cand)\n",
    "            # check whether to sample the instance or not\n",
    "            sampled_indices = delay_wrapper.query(X_cand, clf=clf, X=np.array(X_train), y=np.array(y_train_current), tX=np.array(tX_train), ty=np.array(ty_train), tX_cand=[tX_cand], ty_cand=[ty_cand], return_utilities=False, acquisitions=acquisitions)\n",
    "            delay_wrapper.update(X_cand, sampled_indices )\n",
    "            # set the entry within the acquisition vector according to the query strategy's decision\n",
    "            acquisitions.append((len(sampled_indices) > 0) )\n",
    "            if len(sampled_indices):\n",
    "                count += 1\n",
    "            \n",
    "            # add the current instance to the training data\n",
    "            tX_train.append(tX_cand)\n",
    "            ty_train.append(ty_cand)\n",
    "            X_train.append(x_t)\n",
    "            y_train.append(y_cand)\n",
    "        # calculate and show the average accuracy \n",
    "        print(\"Delay Wrapper: \", delay_wrapper_name, \", Avg Accuracy: \", np.sum(correct_classifications)/stream_length,  \", Number of acquired instances: \", count)\n",
    "        # smoothing the accuracy for plotting\n",
    "        smoothing_window_length = 100\n",
    "        cumsum_correct_classifications = np.cumsum(correct_classifications)\n",
    "        plt.plot((cumsum_correct_classifications[smoothing_window_length:]-cumsum_correct_classifications[:-smoothing_window_length])/smoothing_window_length, label=delay_wrapper_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b214dd2c9a44f12a1833edb4921179114be61850b6456c57ef3370ef440c7a3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('scikit-activeml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
